#!/usr/bin/env python2
#
# Copyright (c) 2012 Felipe Contreras
#

#
# Just copy to your ~/bin, or anywhere in your $PATH.
# Then you can clone with:
# % git clone bzr::/path/to/bzr/repo/or/url
#
# For example:
# % git clone bzr::$HOME/myrepo
# or
# % git clone bzr::lp:myrepo
#
# If you want to specify which branches you want to track (per repo):
# % git config remote.origin.bzr-branches 'trunk, devel, test'
#
# Where 'origin' is the name of the repository you want to specify the
# branches.
#

import sys

import bzrlib
if hasattr(bzrlib, "initialize"):
    bzrlib.initialize(stdout=sys.stderr)

import bzrlib.plugin
bzrlib.plugin.load_plugins()

import bzrlib.generate_ids
import bzrlib.transport
import bzrlib.errors
import bzrlib.ui
import bzrlib.urlutils
import bzrlib.branch

import sys
import os
import json
import re
import StringIO
import atexit
import shutil
import hashlib
import urlparse
import subprocess
import codecs

NAME_RE = re.compile('^([^<>]+)')
AUTHOR_RE = re.compile('^([^<>]+?)? ?[<>]([^<>]*)(?:$|>)')
EMAIL_RE = re.compile(r'([^ \t<>]+@[^ \t<>]+)')
RAW_AUTHOR_RE = re.compile('^(\w+) (.+)? <(.*)> (\d+) ([+-]\d+)')

def die(msg, *args):
    sys.stderr.write('ERROR: %s\n' % (msg % args))
    sys.exit(1)

def warn(msg, *args):
    sys.stderr.write('WARNING: %s\n' % (msg % args))

def gittz(tz):
    return '%+03d%02d' % (tz / 3600, tz % 3600 / 60)

def get_config(config):
    cmd = ['git', 'config', '--get', config]
    process = subprocess.Popen(cmd, stdout=subprocess.PIPE)
    output, _ = process.communicate()
    return output

class GitMarks:

    def __init__(self, path):
      self.path = path
      self.clear()
      self.load()

    def clear(self):
        self.marks = {}
        self.rev_marks = {}

    def load(self):
        if not os.path.exists(self.path):
            return

        for l in file(self.path):
            m, c = l.strip().split(' ', 2)
            m = int(m[1:])
            self.marks[c] = m
            self.rev_marks[m] = c

    def store(self):
        marks = self.rev_marks.keys()
        marks.sort()
        with open(self.path, 'w') as f:
            for m in marks:
                f.write(':%d %s\n' % (m, self.rev_marks[m]))

    def from_rev(self, rev):
        return self.marks[rev]

    def to_rev(self, mark):
        return str(self.rev_marks[mark])

class Marks:

    def __init__(self, path):
        self.path = path
        self.tips = {}
        self.marks = {}
        self.rev_marks = {}
        self.last_mark = 0
        self.load()

    def load(self):
        if not os.path.exists(self.path):
            return

        tmp = json.load(open(self.path))
        self.tips = []
        self.marks = tmp['marks']
        self.last_mark = tmp['last-mark']

        for rev, mark in self.marks.iteritems():
            self.rev_marks[mark] = rev

    def dict(self):
        return { 'tips': self.tips, 'marks': self.marks, 'last-mark': self.last_mark }

    def store(self):
        json.dump(self.dict(), open(self.path, 'w'))

    def __str__(self):
        return str(self.dict())

    def from_rev(self, rev):
        return self.marks[rev]

    def to_rev(self, mark):
        return str(self.rev_marks[mark])

    def next_mark(self):
        self.last_mark += 1
        return self.last_mark

    def get_mark(self, rev):
        self.last_mark += 1
        self.marks[rev] = self.last_mark
        return self.last_mark

    def is_marked(self, rev):
        return rev in self.marks

    def new_mark(self, rev, mark):
        self.marks[rev] = mark
        self.rev_marks[mark] = rev
        self.last_mark = mark

class ParserContext:

    def __init__(self):
        # known context attributes
        self.localref = None
        self.remoteref = None
        self.revs = []

class Parser:

    def __init__(self, repo, cmdstream=sys.stdin, ctx=ParserContext()):
        self.repo = repo
        self.cmdstream = cmdstream
        self.line = self.get_line()
        self.context = ctx

    def get_line(self):
        return self.cmdstream.readline().strip()

    def __getitem__(self, i):
        return self.line.split()[i]

    def check(self, word):
        return self.line.startswith(word)

    def each_block(self, separator):
        while self.line != separator:
            yield self.line
            self.line = self.get_line()

    def __iter__(self):
        return self.each_block('')

    def next(self):
        self.line = self.get_line()
        if self.line == 'done':
            self.line = None

    def get_mark(self):
        i = self.line.index(':') + 1
        return int(self.line[i:])

    def get_data(self):
        if not self.check('data'):
            return None
        i = self.line.index(' ') + 1
        size = int(self.line[i:])
        return self.cmdstream.read(size)

    def get_author(self):
        m = RAW_AUTHOR_RE.match(self.line)
        if not m:
            return None
        _, name, email, date, tz = m.groups()
        name = name.decode('utf-8')
        committer = '%s <%s>' % (name, email)
        tz = int(tz)
        tz = ((tz / 100) * 3600) + ((tz % 100) * 60)
        return (committer, int(date), tz)

def rev_to_mark(rev):
    return marks.from_rev(rev)

def mark_to_rev(mark):
    return marks.to_rev(mark)

def fixup_user(user):
    name = mail = None
    user = user.replace('"', '')
    m = AUTHOR_RE.match(user)
    if m:
        name = m.group(1)
        mail = m.group(2).strip()
    else:
        m = EMAIL_RE.match(user)
        if m:
            mail = m.group(1)
        else:
            m = NAME_RE.match(user)
            if m:
                name = m.group(1).strip()

    if not name:
        name = 'unknown'
    if not mail:
        mail = 'Unknown'

    return '%s <%s>' % (name, mail)

def get_filechanges(cur, prev):
    modified = {}
    removed = {}

    changes = cur.changes_from(prev)

    def u(s):
        return s.encode('utf-8')

    for path, fid, kind in changes.added:
        modified[u(path)] = fid
    for path, fid, kind in changes.removed:
        removed[u(path)] = None
    for path, fid, oldkind, newkind in changes.kind_changed:
        modified[u(path)] = fid
    for path, fid, kind, mod, _ in changes.modified:
        modified[u(path)] = fid
    for oldpath, newpath, fid, kind, mod, _ in changes.renamed:
        removed[u(oldpath)] = None
        if kind == 'directory':
            lst = cur.list_files(from_dir=newpath, recursive=True)
            for path, file_class, kind, fid, entry in lst:
                if kind != 'directory':
                    modified[u(newpath + '/' + path)] = fid
        else:
            modified[u(newpath)] = fid

    return modified, removed

def export_files(tree, files):
    final = []
    for path, fid in files.iteritems():
        kind = tree.kind(fid)

        h = tree.get_file_sha1(fid)

        if kind == 'symlink':
            d = tree.get_symlink_target(fid)
            mode = '120000'
        elif kind == 'file':

            if tree.is_executable(fid):
                mode = '100755'
            else:
                mode = '100644'

            # is the blob already exported?
            if h in filenodes:
                mark = filenodes[h]
                final.append((mode, mark, path))
                continue

            d = tree.get_file_text(fid)
        elif kind == 'directory':
            continue
        else:
            die("Unhandled kind '%s' for path '%s'" % (kind, path))

        mark = marks.next_mark()
        filenodes[h] = mark

        print "blob"
        print "mark :%u" % mark
        print "data %d" % len(d)
        print d

        final.append((mode, mark, path))

    return final

def export_branch(repo, name):
    ref = '%s/heads/%s' % (prefix, name)
    tip = None

    branch = get_remote_branch(name)
    repo = branch.repository

    branch.lock_read()
    revs = branch.iter_merge_sorted_revisions(None, tip, 'exclude', 'forward')
    try:
        tip_revno = 0
        last_revno, _ = branch.last_revision_info()
        total = last_revno - tip_revno
    except bzrlib.errors.NoSuchRevision:
        tip_revno = 0
        total = 0

    notes = set()
    for revid, _, seq, _ in revs:

        if marks.is_marked(revid):
            continue

        rev = repo.get_revision(revid)
        revno = seq[0]
        notes.add(revid)

        parents = rev.parent_ids
        time = rev.timestamp
        tz = rev.timezone
        committer = rev.committer.encode('utf-8')
        authors = rev.get_apparent_authors()
        if authors:
            author = authors[0].encode('utf-8')
        else:
            author = committer

        committer = "%s %u %s" % (fixup_user(committer), time, gittz(tz))
        author = "%s %u %s" % (fixup_user(author), time, gittz(tz))

        author = rev.properties.get('git-author', author.decode('utf-8', 'replace')).encode('utf8')
        committer = rev.properties.get('git-committer', committer.decode('utf-8', 'replace')).encode('utf8')

        msg = rev.message.encode('utf-8')

        msg += '\n'

        if 'git-commit-message-base64' in rev.properties:
            try:
                msg = codecs.decode(rev.properties['git-commit-message-base64'], 'base64')
            except:
                pass

        if rev.properties.has_key('file-info'):
            from bzrlib import bencode
            try:
                files = bencode.bdecode(rev.properties['file-info'].encode('utf-8'))
            except Exception, e:
                # protect against repository corruption
                # (happens in the wild, see MySQL tree)
                files = ()

            rmsg = msg.rstrip('\r\n ')
            file_comments = []
            for file in files:
              fmsg = file['message'].rstrip('\r\n ')
              # Skip empty file comments and file comments identical to the
              # commit comment (they originate from tools and policies that
              # require writing per-file comments and users simply copy-paste
              # revision comment over, these comments add no value as a part of
              # the commit comment).
              if fmsg == '' or fmsg == rmsg:
                  continue

              file_comments.append(file['path'] + ':')
              for l in fmsg.split('\n'):
                  file_comments.append('  ' + l)

            msg += '\n' + '\n'.join(file_comments) + '\n'

        if len(parents) == 0:
            parent = bzrlib.revision.NULL_REVISION
        else:
            parent = parents[0]

        cur_tree = repo.revision_tree(revid)
        prev = repo.revision_tree(parent)
        modified, removed = get_filechanges(cur_tree, prev)

        modified_final = export_files(cur_tree, modified)

        if len(parents) == 0:
            print 'reset %s' % ref

        print "commit %s" % ref
        print "mark :%d" % (marks.get_mark(revid))
        print "author %s" % (author)
        print "committer %s" % (committer)
        print "data %d" % (len(msg))
        print msg

        for i, p in enumerate(parents):
            try:
                m = rev_to_mark(p)
            except KeyError:
                # ghost?
                continue
            if i == 0:
                print "from :%s" % m
            else:
                print "merge :%s" % m

        for f in removed:
            print "D %s" % (f,)
        for f in modified_final:
            print "M %s :%u %s" % f
        print

        if len(seq) > 1:
            # let's skip branch revisions from the progress report
            continue

        progress = (revno - tip_revno)
        if (progress % 100 == 0):
            if total:
                print "progress revision %d '%s' (%d/%d)" % (revno, name, progress, total)
            else:
                print "progress revision %d '%s' (%d)" % (revno, name, progress)

    branch.unlock()

    revid = branch.last_revision()

    # make sure the ref is updated
    print "reset %s" % ref
    print "from :%u" % rev_to_mark(revid)
    print

    # update notes
    desc = 'Notes for %s\n' % name
    update_notes(notes, desc, False)

def export_tag(repo, name):
    ref = '%s/tags/%s' % (prefix, name)
    print "reset %s" % ref
    print "from :%u" % rev_to_mark(tags[name])
    print

def export_head(repo):
    name = master_branch
    export_branch(repo, name)

def do_import(parser):
    repo = parser.repo
    path = os.path.join(marksdir, 'marks-git')

    print "feature done"
    if os.path.exists(path):
        print "feature import-marks=%s" % path
    print "feature export-marks=%s" % path
    print "feature force"
    sys.stdout.flush()

    while parser.check('import'):
        ref = parser[1]
        if ref == 'HEAD':
            export_head(repo)
        elif ref.startswith('refs/heads/'):
            name = ref[len('refs/heads/'):]
            export_branch(repo, name)
        elif ref.startswith('refs/tags/'):
            name = ref[len('refs/tags/'):]
            export_tag(repo, name)
        parser.next()

    print 'done'

    sys.stdout.flush()

def parse_blob(parser):
    parser.next()
    mark = parser.get_mark()
    parser.next()
    data = parser.get_data()
    blob_marks[mark] = data
    parser.next()

class CustomTree():

    def __init__(self, branch, revid, parents, files):
        self.updates = {}
        self.branch = branch

        def copy_tree(revid):
            files = files_cache[revid] = {}
            branch.lock_read()
            tree = branch.repository.revision_tree(revid)
            try:
                for path, entry in tree.iter_entries_by_dir():
                    files[path] = [entry.file_id, None]
            finally:
                branch.unlock()
            return files

        if len(parents) == 0:
            self.base_id = bzrlib.revision.NULL_REVISION
            self.base_files = {}
        else:
            self.base_id = parents[0]
            self.base_files = files_cache.get(self.base_id, None)
            if not self.base_files:
                self.base_files = copy_tree(self.base_id)

        self.files = files_cache[revid] = self.base_files.copy()
        self.rev_files = {}

        for path, data in self.files.iteritems():
            fid, mark = data
            self.rev_files[fid] = [path, mark]

        for path, f in files.iteritems():
            fid, mark = self.files.get(path, [None, None])
            if not fid:
                fid = bzrlib.generate_ids.gen_file_id(path)
            f['path'] = path
            self.rev_files[fid] = [path, mark]
            self.updates[fid] = f

    def last_revision(self):
        return self.base_id

    def iter_changes(self):
        changes = []

        def get_parent(dirname, basename):
            parent_fid, mark = self.base_files.get(dirname, [None, None])
            if parent_fid:
                return parent_fid
            parent_fid, mark = self.files.get(dirname, [None, None])
            if parent_fid:
                return parent_fid
            if basename == '':
                return None
            fid = bzrlib.generate_ids.gen_file_id(path)
            add_entry(fid, dirname, 'directory')
            return fid

        def add_entry(fid, path, kind, mode=None):
            dirname, basename = os.path.split(path)
            parent_fid = get_parent(dirname, basename)

            executable = False
            if mode == '100755':
                executable = True
            elif mode == '120000':
                kind = 'symlink'

            change = (fid,
                    (None, path),
                    True,
                    (False, True),
                    (None, parent_fid),
                    (None, basename),
                    (None, kind),
                    (None, executable))
            self.files[path] = [change[0], None]
            changes.append(change)

        def update_entry(fid, path, kind, mode=None):
            dirname, basename = os.path.split(path)
            parent_fid = get_parent(dirname, basename)

            executable = False
            if mode == '100755':
                executable = True
            elif mode == '120000':
                kind = 'symlink'

            change = (fid,
                    (path, path),
                    True,
                    (True, True),
                    (None, parent_fid),
                    (None, basename),
                    (None, kind),
                    (None, executable))
            self.files[path] = [change[0], None]
            changes.append(change)

        def remove_entry(fid, path, kind):
            dirname, basename = os.path.split(path)
            parent_fid = get_parent(dirname, basename)
            change = (fid,
                    (path, None),
                    True,
                    (True, False),
                    (parent_fid, None),
                    (None, None),
                    (None, None),
                    (None, None))
            del self.files[path]
            changes.append(change)

        for fid, f in self.updates.iteritems():
            path = f['path']

            if 'deleted' in f:
                remove_entry(fid, path, 'file')
                continue

            if path in self.base_files:
                update_entry(fid, path, 'file', f['mode'])
            else:
                add_entry(fid, path, 'file', f['mode'])

            self.files[path][1] = f['mark']
            self.rev_files[fid][1] = f['mark']

        return changes

    def get_content(self, file_id):
        path, mark = self.rev_files[file_id]
        if mark:
            return blob_marks[mark]

        # last resort
        tree = self.branch.repository.revision_tree(self.base_id)
        return tree.get_file_text(file_id)

    def get_file_with_stat(self, file_id, path=None):
        content = self.get_content(file_id)
        return (StringIO.StringIO(content), None)

    def get_symlink_target(self, file_id):
        return self.get_content(file_id)

    def id2path(self, file_id):
        path, mark = self.rev_files[file_id]
        return path

def c_style_unescape(string):
    if string[0] == string[-1] == '"':
        return string.decode('string-escape')[1:-1]
    return string

def parse_commit(parser):
    parents = []

    ref = parser[1]
    remoteref = parser.context.remoteref
    ref = parser[1] if not remoteref else remoteref
    parser.next()

    if ref.startswith('refs/heads/'):
        name = ref[len('refs/heads/'):]
        branch = get_remote_branch(name, True)
    else:
        # fall-back to master branch
        # only the underlying repository shared storage is needed anyway
        branch = get_remote_branch(master_branch)

    commit_mark = parser.get_mark()
    parser.next()
    author = parser.get_author()
    author_raw = parser.line.decode("utf8")
    parser.next()
    committer = parser.get_author()
    committer_raw = parser.line.decode("utf8")
    parser.next()
    data = parser.get_data()
    parser.next()
    if parser.check('from'):
        parents.append(parser.get_mark())
        parser.next()
    while parser.check('merge'):
        parents.append(parser.get_mark())
        parser.next()

    original_commit_msg = data

    # fast-export adds an extra newline (sometimes)
    if data[-1] == '\n':
        data = data[:-1]
    data = data.replace('\r','')

    # bzr does not accept \r
    data = data.replace('\r','')

    files = {}

    for line in parser:
        if parser.check('M'):
            t, m, mark_ref, path = line.split(' ', 3)
            mark = int(mark_ref[1:])
            f = { 'mode': m, 'mark': mark }
        elif parser.check('D'):
            t, path = line.split(' ', 1)
            f = { 'deleted': True }
        else:
            die('Unknown file command: %s' % line)
        path = c_style_unescape(path).decode('utf-8')
        files[path] = f

    committer, date, tz = committer
    author, _, _ = author
    parents = [mark_to_rev(p) for p in parents]
    revid = bzrlib.generate_ids.gen_revision_id(committer, date)
    props = {}
    props['branch-nick'] = branch.nick
    props['authors'] = author

    committer_rt = "comitter %s %u %s" % (fixup_user(committer), date, gittz(tz))
    author_rt = "author %s %u %s" % (fixup_user(author), date, gittz(tz))

    # write special commit properties with original raw data in those cases
    # where the normal restoration from bzr to git would not reproduce them.
    if author_rt != author_raw and author_raw.startswith('author '):
        props['git-author'] = author_raw[len('author '):]
    if committer_rt != committer_raw and committer_raw.startswith('committer '):
        props['git-committer'] = committer_raw[len('committer '):]
    if original_commit_msg != data + '\n':
        props['git-commit-message-base64'] = codecs.encode(original_commit_msg, 'base64')

    mtree = CustomTree(branch, revid, parents, files)
    changes = mtree.iter_changes()

    branch.lock_write()
    try:
        builder = branch.get_commit_builder(parents, None, date, tz, committer, props, revid)
        try:
            list(builder.record_iter_changes(mtree, mtree.last_revision(), changes))
            builder.finish_inventory()
            builder.commit(data.decode('utf-8', 'replace'))
        except Exception, e:
            builder.abort()
            raise
    finally:
        branch.unlock()

    parsed_refs[ref] = revid
    marks.new_mark(revid, commit_mark)
    parser.context.revs.append(revid)

def parse_reset(parser):
    ref = parser[1]
    remoteref = parser.context.remoteref
    ref = parser[1] if not remoteref else remoteref
    parser.next()

    # ugh
    if parser.check('commit'):
        parse_commit(parser)
        return
    if not parser.check('from'):
        return
    from_mark = parser.get_mark()
    parser.next()

    parsed_refs[ref] = mark_to_rev(from_mark)

def select_tag_branch(refs):
    heads = [ref[len('refs/heads/'):] for ref in refs if ref.startswith('refs/heads')]
    bname = os.getenv('BZR_BRANCH', None)
    # environment setting always wins,
    # otherwise auto-select if only 1 reasonable suggestion
    if len(branches) == 1 and not bname:
        bname = branches.keys()[0]
    if len(heads) == 1 and not bname:
        bname = heads[0]
    return bname

def git_rev_parse(ref):
    cmd = ['git', 'rev-parse', '--verify', '-q', ref]
    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    gc, _ = process.communicate()
    gc = gc.strip()
    return gc

def get_bzr_revid(ref):
    gc = git_rev_parse(ref)
    try:
        marks_path = os.path.join(marksdir, 'marks-git')
        gitmarks = GitMarks(marks_path)
        m = gitmarks.from_rev(gc)
        revid = marks.to_rev(m)
    except:
        revid = None
    return revid

def do_export(parser):
    global parsed_refs
    parsed_refs = {}

    parser.next()

    remoteref = parser.context.remoteref
    if remoteref and not parser.line:
        # if remoteref is in past exported
        # git-fast-export might not produce anything at all
        # that is ok'ish, we will determine parsed_ref another way
        localref = parser.context.localref
        revid = get_bzr_revid(localref)
        if not revid:
            # maybe the notes are not updated
            # happens only on fetch for now ... let's ask for that
            print "error %s no revid for ref %s" % (remoteref, localref)
            return False
        parsed_refs[remoteref] = revid
        # now make parser happy
        parser.line = 'done'

    for line in parser.each_block('done'):
        if parser.check('blob'):
            parse_blob(parser)
        elif parser.check('commit'):
            parse_commit(parser)
        elif parser.check('reset'):
            parse_reset(parser)
        elif parser.check('tag'):
            pass
        elif parser.check('feature'):
            pass
        else:
            die('unhandled export command: %s' % line)

    success = True
    for ref, revid in parsed_refs.iteritems():
        if force_need_fetch:
            print "error %s marks files changed to shared; need to fetch first" % ref
            continue
        if ref.startswith('refs/heads/'):
            name = ref[len('refs/heads/'):]
            branch = get_remote_branch(name, True)
            # a proxy branch is now always used
            # following sets it to the targeted ref
            # then we will push from there (diverged or not) minding dry-run
            branch.generate_revision_history(revid)

            if not name in peers and not dry_run:
                # new branch within repo, or new branch/repo altogether
                location = bzrlib.urlutils.join(url, name) if parser.repo else url
                to_transport = bzrlib.transport.get_transport(location)
                try:
                    br_to = branch.create_clone_on_transport(to_transport)
                except:
                    print "error %s rejected" % ref
                    success = False
                    continue

            if name in peers:
                peer = bzrlib.branch.Branch.open(peers[name],
                                                 possible_transports=transports)
                # dry-run; check but no push
                if dry_run and not force:
                    peer.lock_read()
                    try:
                        cur_tip = peer.last_revision()
                        if not peer.repository.get_graph().is_ancestor(cur_tip, revid):
                            print "error %s non-fast forward" % ref
                            success = False
                        else:
                            print "ok %s" % ref
                    finally:
                        peer.unlock()
                    continue

                # really push
                try:
                    peer.bzrdir.push_branch(branch, revision_id=revid,
                                            overwrite=force)
                except bzrlib.errors.DivergedBranches:
                    print "error %s non-fast forward" % ref
                    success = False
                    continue

            try:
                wt = branch.bzrdir.open_workingtree()
                wt.update()
            except bzrlib.errors.NoWorkingTree:
                pass
        elif ref.startswith('refs/tags/'):
            # the mapping from a branch (which is conceptually a bzr repo) to
            # a git branch is a bit skewed, since now we do not really know
            # to which bzr branch/repo to push this tag to
            # all of them seems excessive, so we will try to pick one cleverly
            tagbranch = select_tag_branch(parsed_refs)
            if not tagbranch or not tagbranch in peers:
                print "error %s set BZR_BRANCH to specify branch to push tag" % ref
                success = False
                continue
            peer = bzrlib.branch.Branch.open(peers[tagbranch],
                                             possible_transports=transports)
            name = ref[len('refs/tags/'):]
            try:
                existing_target = peer.tags.lookup_tag(name)
            except bzrlib.errors.NoSuchTag:
                existing_target = None
            if not force and existing_target not in (None, revid):
                print "error %s already exists" % ref
                success = False
                continue
            if existing_target == revid:
                print "ok %s up to date" % ref
                continue
            elif not dry_run:
                peer.tags.set_tag(name, revid)
        else:
            # transport-helper/fast-export bugs
            continue

        print "ok %s" % ref

    return success

def delete_branch(parser, ref):
    bname = ref[len('refs/heads/'):]
    # delete local (proxy or target)
    ok = True
    try:
        if bname in branches:
            branch = get_remote_branch(bname)
            branch.bzrdir.destroy_branch(branch.name)
            branch = None
            branch_path = os.path.join(dirname, 'clone', bname)
            if os.path.exists(branch_path):
                shutil.rmtree(branch_path)
        if bname in peers:
            peer = bzrlib.branch.Branch.open(peers[bname],
                                            possible_transports=transports)
            peer.bzrdir.destroy_branch(peer.name)
    except:
        ok = False
    # delete private ref
    if ok:
        pref = '%s/heads/%s' % (prefix, bname)
        subprocess.call(['git', 'update-ref', '-d', pref])
    return ok

def do_push_refspec(parser, refspec, revs):
    global force

    force = (refspec[0] == '+')
    refs = refspec.strip('+').split(':')
    # check for delete
    if (not refs[0]) and refs[1].startswith('refs/heads'):
        if not dry_run and not delete_branch(parser, refs[1]):
            print "error %s could not delete"% (refs[1])
        else:
            print "ok %s" % (refs[1])
        return
    # sanity check on remote ref
    if not (refs[1].startswith('refs/heads') or refs[1].startswith('refs/tags')):
        print "error %s refspec not supported " % refs[1]
        return
    ctx = ParserContext()
    if refs[0] != refs[1]:
        ctx.remoteref = refs[1]
        ctx.localref = refs[0]
    # ok, fire up git-fast-export and process it
    cmd = ['git', 'fast-export', '--use-done-feature']
    fast_export_options = get_config('remote-bzr.fast-export-options')
    if not fast_export_options:
        # nothing special here since move/copy not handled (yet?)
        fast_export_options = ''
    cmd.extend(fast_export_options.strip().split())
    marks = os.path.join(marksdir, 'marks-git')
    if os.path.exists(marks):
        cmd.append('--import-marks=%s' % marks)
    # no commit of marks if dry_run
    # and only commit if all went ok,
    # otherwise some commits may no longer be exported next time/try around
    tmpmarks = ''
    if not dry_run:
        tmpmarks = os.path.join(marksdir, 'marks-git-%d' % (os.getpid()))
        cmd.append('--export-marks=%s' % tmpmarks)
    cmd.append(refs[0])
    export = subprocess.Popen(cmd, stdin=None, stdout=subprocess.PIPE)
    ok = False
    try:
        nparser = Parser(parser.repo, export.stdout, ctx)
        ok = do_export(nparser)
    finally:
        if tmpmarks and os.path.exists(tmpmarks):
            if ok and not dry_run:
                # the commits made it through, now we can commit
                os.rename(tmpmarks, marks)
                revs[:] = nparser.context.revs
            else:
                os.remove(tmpmarks)

def update_notes(revs, desc, run_import):
    global last_note
    if not 'last_note' in globals():
        last_note = 0

    if not revs:
        return True

    if run_import:
        # spin up fast-import
        gitmarks = os.path.join(marksdir, 'marks-git')
        # marks should exist by now
        # no export of marks since notes commits are not relevant
        proc = subprocess.Popen(['git', 'fast-import', '--done', '--quiet',
            '--import-marks=%s' % gitmarks], stdin=subprocess.PIPE, stdout=sys.stderr)
        # now feed fast-import
        dest = proc.stdin
    else:
        proc = None
        dest = sys.stdout

    import time as ptime
    note_mark = marks.next_mark()
    ref = "refs/notes/bzr"
    dest.write("commit %s\n" % ref)
    dest.write("mark :%d\n" % (note_mark))
    dest.write("committer remote-bzr <> %d %s\n" % (ptime.time(), gittz(ptime.timezone)))
    dest.write("data %d\n" % (len(desc)))
    dest.write(desc + '\n')
    # continue incrementally on current notes branch (whenever possible)
    # to avoid wiping out present content upon fetch of new repo
    # but track along with the previous ref as import goes along
    current_note = git_rev_parse(ref)
    if current_note and not last_note:
        dest.write("from %s^0\n" % (ref))
    elif last_note:
        dest.write("from :%u\n" % last_note)
    for rev in revs:
        dest.write("N inline :%u\n" % marks.from_rev(rev))
        dest.write("data %d\n" % (len(rev)))
        dest.write(rev + '\n')
    dest.write('\n')
    last_note = note_mark

    if proc:
        dest.write('done\n')
        dest.flush()
        proc.wait()
        # fail hard if this fails
        # that prevents the marks file from being written
        # so we can have a fresh look with a fetch
        if proc.returncode:
            die('notes update failed with return %d; recover with git fetch' %
                (proc.returncode))

def do_push(parser):
    if os.environ.get('GIT_REMOTE_BZR_DEBUG_PUSH'):
        dump = ''
        for line in parser:
            dump += line + '\n'
        die('DEBUG push:\n%s' % (dump))
    revs = []
    for line in parser:
        if parser.check('push'):
            localrevs = []
            do_push_refspec(parser, line.lstrip('push '), localrevs)
            revs.extend(localrevs)
        else:
            die('unhandled push command: %s' % (line))
    print
    # at this stage, all external processes are done, marks files written
    # so we can use those to update notes
    update_notes(revs, "Update notes on push", True)

def do_capabilities(parser):
    print "import"
    print "push"
    print "refspec refs/heads/*:%s/heads/*" % prefix
    print "refspec refs/tags/*:%s/tags/*" % prefix

    path = os.path.join(marksdir, 'marks-git')

    if os.path.exists(path):
        print "*import-marks %s" % path
    print "*export-marks %s" % path

    print "option"
    # nothing really depends on the private refs being up to date
    # (export is limited anyway by the current git marks)
    # and they are not always updated correctly (dry-run, bookmark delete, ...)
    # (might resolve some dry-run breakage also)
    print "no-private-update"
    print

class InvalidOptionValue(Exception):
    pass

def get_bool_option(val):
    if val == 'true':
        return True
    elif val == 'false':
        return False
    else:
        raise InvalidOptionValue()

def do_option(parser):
    global dry_run, force
    opt, val = parser[1:3]
    try:
        if opt == 'force':
            force = get_bool_option(val)
            print 'ok'
        elif opt == 'dry-run':
            dry_run = get_bool_option(val)
            print 'ok'
        else:
            print 'unsupported'
    except InvalidOptionValue:
        print "error '%s' is not a valid value for option '%s'" % (val, opt)

def ref_is_valid(name):
    return True not in [c in name for c in '~^: \\']

def do_list(parser):
    global master_branch

    for_push = (parser.line.find('for-push') >= 0)
    parser.repo = get_repo(url, alias, for_push)
    # for export command a ref's old_sha1 was taken from private namespace ref
    # for push command a fake one is provided
    # that avoids having the ref status reported as a new branch/tag
    # (though it will be marked as FETCH_FIRST prior to push,
    # but that's ok as we will provide proper status)
    sha1 = 'f' * 40 if (for_push) else '?'

    for name in branches:
        if not master_branch:
            master_branch = name
        print "%s refs/heads/%s" % (sha1, name)

    if not master_branch:
        print
        return

    branch = get_remote_branch(master_branch)
    branch.lock_read()
    for tag, revid in branch.tags.get_tag_dict().items():
        try:
            branch.revision_id_to_dotted_revno(revid)
        except bzrlib.errors.NoSuchRevision:
            continue
        if not ref_is_valid(tag):
            continue
        print "%s refs/tags/%s" % (sha1, tag)
        tags[tag] = revid
    branch.unlock()

    print "@refs/heads/%s HEAD" % master_branch
    print

def clone(path, remote_branch):
    try:
        bdir = bzrlib.bzrdir.BzrDir.create(path, possible_transports=transports)
    except bzrlib.errors.AlreadyControlDirError:
        bdir = bzrlib.bzrdir.BzrDir.open(path, possible_transports=transports)
    repo = bdir.find_repository()
    repo.fetch(remote_branch.repository)
    return remote_branch.sprout(bdir, repository=repo)

def create_proxy_branch(name):
    def try_branch_open(location):
        bb = None
        if os.path.exists(location):
            try:
                bb = bzrlib.branch.Branch.open(location)
            except:
                pass
        return bb
    # just need another place to store a branch tip
    # so clone something we have
    mb = None
    for b in branches:
        location = os.path.join(dirname, 'clone', b)
        mb = try_branch_open(location)
        if mb:
            break
    # no suitable source branch within this repo
    # maybe repo does not exist yet, let's broaden search
    if not mb:
        for d in os.listdir(os.path.join(gitdir, 'bzr')):
            cdir = os.path.join(gitdir, 'bzr', d, 'clone')
            if d == '.bzr' or not os.path.isdir(cdir):
                continue
            for b in os.listdir(cdir):
                location = os.path.join(cdir, b)
                mb = try_branch_open(location)
                if mb:
                    break
            if mb:
                break
    if not mb:
        die('could not create branch; fetch first')
    location = os.path.join(dirname, 'clone', name)
    # ensure clean slate start
    if os.path.exists(location):
        shutil.rmtree(location)
    cdir = os.path.join(dirname, 'clone')
    if not os.path.exists(cdir):
        os.makedirs(cdir)
    return mb.bzrdir.sprout(location, create_tree_if_local=False).open_branch()

def get_remote_branch(name, create=False):
    global proxys
    if not 'proxys' in globals():
        proxys = {}
    # use a branch cache to avoid fetching upon every call
    # (which would amount to every commit when pushing)
    branch = proxys.get(name, None)
    if branch:
        return branch

    if not name in branches and create:
        branch = create_proxy_branch(name)
        proxys[name] = branch
        return branch

    remote_branch = bzrlib.branch.Branch.open(branches[name],
                                              possible_transports=transports)
    if not local_proxy and \
      isinstance(remote_branch.bzrdir.root_transport, bzrlib.transport.local.LocalTransport):
        return remote_branch

    branch_path = os.path.join(dirname, 'clone', name)

    # all this could take some doing, so show some progress
    show_ui(True)

    try:
        branch = bzrlib.branch.Branch.open(branch_path,
                                           possible_transports=transports)
    except bzrlib.errors.NotBranchError:
        # clone
        branch = clone(branch_path, remote_branch)
    else:
        # pull
        try:
            branch.pull(remote_branch, overwrite=True)
        except bzrlib.errors.DivergedBranches:
            # use remote branch for now
            branch = remote_branch

    show_ui(False)

    proxys[name] = branch
    return branch

def find_branches(repo):
    transport = repo.bzrdir.root_transport

    for fn in transport.iter_files_recursive():
        if not fn.endswith('.bzr/branch-format'):
            continue

        name = subdir = fn[:-len('/.bzr/branch-format')]
        name = name if name != '' else 'master'
        name = name.replace('/', '+')

        try:
            cur = transport.clone(subdir)
            branch = bzrlib.branch.Branch.open_from_transport(cur)
        except (bzrlib.errors.NotBranchError, bzrlib.errors.PermissionDenied):
            continue
        else:
            yield name, branch.base

def get_repo(url, alias, nothrow=True):
    normal_url = bzrlib.urlutils.normalize_url(url)
    try:
        origin = bzrlib.bzrdir.BzrDir.open(url, possible_transports=transports)
    except bzrlib.errors.NotBranchError:
        # allow create-upon-push to LaunchPad
        if nothrow and url[0:3] == 'lp:':
            return None
        raise
    is_local = isinstance(origin.transport, bzrlib.transport.local.LocalTransport)
    is_local = False if local_proxy else is_local

    shared_path = os.path.join(gitdir, 'bzr')
    try:
        shared_dir = bzrlib.bzrdir.BzrDir.open(shared_path,
                                               possible_transports=transports)
    except bzrlib.errors.NotBranchError:
        shared_dir = bzrlib.bzrdir.BzrDir.create(shared_path,
                                                 possible_transports=transports)
    try:
        shared_repo = shared_dir.open_repository()
    except bzrlib.errors.NoRepositoryPresent:
        shared_repo = shared_dir.create_repository(shared=True)

    if not is_local:
        clone_path = os.path.join(dirname, 'clone')
        if not os.path.exists(clone_path):
            os.mkdir(clone_path)
        else:
            # check and remove old organization
            try:
                bdir = bzrlib.bzrdir.BzrDir.open(clone_path,
                                                 possible_transports=transports)
                bdir.destroy_repository()
            except bzrlib.errors.NotBranchError:
                pass
            except bzrlib.errors.NoRepositoryPresent:
                pass

    wanted = get_config('remote.%s.bzr-branches' % alias).rstrip().split(', ')
    # stupid python
    wanted = [e for e in wanted if e]
    if not wanted:
        wanted = get_config('remote-bzr.branches').rstrip().split(', ')
        # stupid python
        wanted = [e for e in wanted if e]

    if not wanted:
        try:
            repo = origin.open_repository()
            if not repo.bzrdir.root_transport.listable():
                # this repository is not usable for us
                raise bzrlib.errors.NoRepositoryPresent(repo.bzrdir)
        except bzrlib.errors.NoRepositoryPresent:
            wanted = ['master']

    if wanted:
        def list_wanted(url, wanted):
            for name in wanted:
                subdir = name if name != 'master' else ''
                yield name, bzrlib.urlutils.join(url, subdir)

        branch_list = list_wanted(url, wanted)
    else:
        branch_list = find_branches(repo)

    for name, url in branch_list:
        if not is_local:
            peers[name] = url
        branches[name] = url

    return origin

def fix_path(alias, orig_url):
    url = urlparse.urlparse(orig_url, 'file')
    if url.scheme != 'file' or os.path.isabs(url.path):
        return
    abs_url = urlparse.urljoin("%s/" % os.getcwd(), orig_url)
    cmd = ['git', 'config', 'remote.%s.url' % alias, "bzr::%s" % abs_url]
    subprocess.call(cmd)

def show_ui(show):
    if hasattr(bzrlib.ui.ui_factory, 'be_quiet'):
        bzrlib.ui.ui_factory.be_quiet(not show)

def select_private_refs(alias):
    # clean the old refs
    refs = subprocess.Popen(['git', 'for-each-ref', \
        '--format=delete %(refname)', 'refs/bzr'], stdout=subprocess.PIPE)
    update = subprocess.Popen(['git', 'update-ref', '--stdin'], stdin=refs.stdout)
    refs.stdout.close()  # helps with SIGPIPE
    update.communicate()
    # keep private implementation refs really private
    return 'bzr/%s/refs' % alias

def select_marks_dir(alias, gitdir):
    global force_need_fetch
    force_need_fetch = False

    # per-alias private marks files
    private_gm = os.path.join(dirname, 'marks-git')
    private_bzr = os.path.join(dirname, 'marks-int')
    # shared marks files
    shared_dir = os.path.join(gitdir, 'bzr')
    shared_gm = os.path.join(shared_dir, 'marks-git')
    shared_bzr = os.path.join(shared_dir, 'marks-int')
    # promote private to shared if no shared yet, otherwise force fetch-first
    for c in ((private_gm, shared_gm), (private_bzr, shared_bzr)):
        p, s = c
        if os.path.exists(p):
            if not os.path.exists(s):
                os.rename(p, s)
            else:
                # only remove when a fetch has been done
                force_need_fetch = True
    return shared_dir

def clean_private_marks_files():
    for p in ('marks-git', 'marks-int'):
        pn = os.path.join(dirname, p)
        if os.path.exists(pn):
            os.remove(pn)

def main(args):
    global marks, prefix, gitdir, dirname
    global tags, filenodes
    global blob_marks
    global parsed_refs
    global files_cache
    global is_tmp
    global branches, peers
    global transports
    global url, alias
    global force
    global dry_run
    global master_branch
    global local_proxy
    global marksdir

    marks = None
    is_tmp = False
    master_branch = None
    gitdir = os.environ.get('GIT_DIR', None)

    if len(args) < 3:
        die('Not enough arguments.')

    if not gitdir:
        die('GIT_DIR not set')

    alias = args[1]
    url = args[2]

    tags = {}
    filenodes = {}
    blob_marks = {}
    parsed_refs = {}
    files_cache = {}
    branches = {}
    peers = {}
    transports = []
    force = False
    dry_run = False
    # also use a proxy repo for a local one;
    # allows dry-run and streamlines lots of stuff
    local_proxy = True

    if alias[5:] == url:
        is_tmp = True
        alias = hashlib.sha1(alias).hexdigest()

    prefix = select_private_refs(alias)
    dirname = os.path.join(gitdir, 'bzr', alias)

    if not is_tmp:
        fix_path(alias, url)

    if not os.path.exists(dirname):
        os.makedirs(dirname)

    show_ui(False)

    marksdir = select_marks_dir(alias, gitdir)
    repo = None # will get it later

    marks_path = os.path.join(marksdir, 'marks-int')
    marks = Marks(marks_path)

    parser = Parser(repo)
    for line in parser:
        if parser.check('capabilities'):
            do_capabilities(parser)
        elif parser.check('list'):
            do_list(parser)
        elif parser.check('import'):
            do_import(parser)
        elif parser.check('push'):
            do_push(parser)
            clean_private_marks_files()
        elif parser.check('option'):
            do_option(parser)
        else:
            die('unhandled command: %s' % line)
        sys.stdout.flush()

    marks.store()

def bye():
    if is_tmp:
        shutil.rmtree(dirname)

atexit.register(bye)
sys.exit(main(sys.argv))
